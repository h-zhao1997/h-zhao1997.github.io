---
permalink: /
title: "Han Zhao 赵晗"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<h2 id='about'>About Me</h2>

Hi! I'm Han Zhao (赵晗). I hold my bachelor's and master's degrees in Control Science and Engineering from <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications</a> (BUPT) in 2020 and 2023, respectively. I am currently a third-year joint Ph.D. student in Computer Science and Technology at <a href="https://www.zju.edu.cn/">Zhejiang University</a> and <a href="https://www.westlake.edu.cn/">Westlake University</a> (<a href="https://milab.westlake.edu.cn/">Machine Intelligence Lab</a>, MiLAB), advised by Prof. Donglin Wang. 


<h2 id='research-interests'>Research Interests</h2>
My current research interests include Embodied Artificial Intelligence, Foundation Models, Reinforcement Learning, and Robotics. 

Specifically, I am interested in:
- **Foundation Models for Robotics**: developing efficient and effective foundation models for robotics, including multi-modal large language models and vision-language-action models to enhance robots' perception and decision-making capabilities.

- **Scalable Reinforcement Learning Algorithms**: developing reinforcement learning algorithms that can effectively manage large-scale data and model capacity for robotic control. This includes methods such as offline reinforcement learning, imitation learning, and more, to enable robots to acquire scalable and generalizable skills.

<!--
- **Motion Planning and Control for Legged Robots**: developing motion planning and control algorithms for legged robots, including bipedal and quadruped robots, to enable them to perform complex tasks in real-world environments.

<h2 id='news'>News</h2>

* **[March 4, 2025]** A new [paper](https://arxiv.org/abs/2503.02310) about accelerating the action decoding process of VLA has been online! Check out the paper and our model PD-VLA!

* **[January 28, 2025]** Two papers ([QUART-Online](https://arxiv.org/abs/2412.15576) and [MoRE](https://arxiv.org/abs/2503.08007)) have been accepted for ICRA 2025!

* **[January 23, 2025]** [VLAS](https://arxiv.org/abs/2502.13508), a work about integrating speech instruction as a new modality into VLA, has been accepted for ICLR 2025!

* **[January 9, 2025]** One paper about control theory with my former supervisor during the master's program has been accepted for Neurocomputing!

* **[December 10, 2024]** [Cobra](https://arxiv.org/abs/2403.14520) have been accepted for AAAI-25!

* **[July 4, 2024]** Two papers ([PiTe](https://arxiv.org/abs/2409.07239) and [QUAR-VLA](https://arxiv.org/abs/2312.14457)) have been accepted for ECCV 2024!

* **[June 30, 2024]** [GeRM](https://arxiv.org/abs/2403.13358) has been accepted for IROS 2024!

* **[May 14, 2024]** One paper (RL2AC) has been accepted for RSS 2024!

* **[March 22, 2024]** A new [paper](https://arxiv.org/abs/2403.14520) about Cobra, an efficient multi-modal large language model, was released. [Project page](https://sites.google.com/view/cobravlm) has been available. The paper has been featured by [Hugging Face Daily Papers](https://huggingface.co/papers?date=2024-03-22)! [Demo](https://huggingface.co/spaces/han1997/cobra) has been available!

* **[March 20, 2024]** A new [paper](https://arxiv.org/abs/2403.13358) about GeRM, a generalist robotic model with the mixture-of-experts architecture and RL training method for quadruped robot, was released. [Project page](https://songwxuan.github.io/GeRM/) has been available. [Video](https://www.youtube.com/watch?v=tjgIxsXW0JU) has been available!
-->


<h2 id='publications'>Publications</h2>

### Preprint

<a href="https://arxiv.org/abs/2510.12276" target="_blank"><img src="https://img.shields.io/badge/arXiv-2510.12276-B31B1B?style=for-the-badge"></a> Fuhao Li, Wenxuan Song, <u>Han Zhao</u>, Jingbo Wang, Pengxiang Ding, Donglin Wang, Long Zeng, Haoang Li\*, &quot;**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**&quot;. [[ArXiv](https://arxiv.org/pdf/2510.12276.pdf)]

<a href="https://arxiv.org/abs/2510.10903" target="_blank"><img src="https://img.shields.io/badge/arXiv-2510.10903-B31B1B?style=for-the-badge"></a> Shuanghao Bai, Wenxuan Song, Jiayi Chen, Yuheng Ji, Zhide Zhong, Jin Yang, <u>Han Zhao</u>, Wanqi Zhou, Wei Zhao, Zhe Li, Pengxiang Ding, Cheng Chi, Haoang Li, Chang Xu, Xiaolong Zheng, Donglin Wang, Shanghang Zhang\*, Badong Chen\*, &quot;**Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey**&quot;. [[ArXiv](https://arxiv.org/pdf/2510.10903.pdf)]

<a href="https://arxiv.org/abs/2509.09372" target="_blank"><img src="https://img.shields.io/badge/arXiv-2509.09372-B31B1B?style=for-the-badge"></a> Yihao Wang, Pengxiang Ding, Lingxiao Li, Can Cui, Zirui Ge, Xinyang Tong, Wenxuan Song, <u>Han Zhao</u>, Wei Zhao, Pengxu Hou, Siteng Huang, Yifan Tang, Wenhui Wang, Ru Zhang, Jianyi Liu, Donglin Wang\*, &quot;**VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model**&quot;. [[ArXiv](https://arxiv.org/pdf/2509.09372.pdf)]

<a href="https://arxiv.org/abs/2508.10333" target="_blank"><img src="https://img.shields.io/badge/arXiv-2508.10333-B31B1B?style=for-the-badge"></a> Wenxuan Song, Ziyang Zhou, <u>Han Zhao</u>, Jiayi Chen, Pengxiang Ding, Haodong Yan, Yuxin Huang, Feilong Tang, Donglin Wang, Haoang Li\*, &quot;**ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver**&quot;. [[ArXiv](https://arxiv.org/pdf/2508.10333.pdf)]

<a href="https://arxiv.org/abs/2505.03912" target="_blank"><img src="https://img.shields.io/badge/arXiv-2505.03912-B31B1B?style=for-the-badge"></a> Can Cui, Pengxiang Ding, Wenxuan Song, Shuanghao Bai, Xinyang Tong, Zirui Ge, Runze Suo, Wanqi Zhou, Yang Liu, Bofang Jia, <u>Han Zhao</u>, Siteng Huang, Donglin Wang\*, &quot;**OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation**&quot;. [[ArXiv](https://arxiv.org/pdf/2505.03912.pdf)]

<a href="https://arxiv.org/abs/2506.13725" target="_blank"><img src="https://img.shields.io/badge/arXiv-2506.13725-B31B1B?style=for-the-badge"></a> Wenxuan Song, Jiayi Chen, Pengxiang Ding, Yuxin Huang, <u>Han Zhao</u>, Donglin Wang, Haoang Li\*, &quot;**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**&quot;. [[ArXiv](https://arxiv.org/pdf/2506.13725.pdf)]

<a href="https://arxiv.org/abs/2506.10826" target="_blank"><img src="https://img.shields.io/badge/arXiv-2506.10826-B31B1B?style=for-the-badge"></a> Wenxuan Song, Jiayi Chen, Wenxue Li, Xu He, <u>Han Zhao</u>, Can Cui, Pengxiang Ding, Shiyan Su, Feilong Tang,
 Donglin Wang, Xuelian Cheng, Zongyuan Ge, Xinhu Zheng, Zhe Liu, Hesheng Wang, Haoang Li, &quot;**RationalVLA: A Rational Vision-Language-Action Model with Dual System**&quot;. [[ArXiv](https://arxiv.org/pdf/2506.10826.pdf)]

<a href="https://arxiv.org/abs/2311.06015" target="_blank"><img src="https://img.shields.io/badge/arXiv-2311.06015-B31B1B?style=for-the-badge"></a> Hongyin Zhang, Diyuan Shi, Zifeng Zhuang, <u>Han Zhao</u>, Zhenyu Wei, Feng Zhao, Sibo Gai, Shangke Lyu, Donglin Wang\*, &quot;**Unlock Reliable Skill Inference for Quadruped Adaptive Behavior by Skill Graph**&quot;. [[ArXiv](https://arxiv.org/abs/2311.06015)]

### 2025
<a target="_blank"><img src="https://img.shields.io/badge/NIPS-2025-blue?style=for-the-badge"></a> Yang Liu, Ming Ma, Xiaomin Yu, Pengxiang Ding, <u>Han Zhao</u>, Mingyang Sun, Siteng Huang, Donglin Wang, &quot;**SSR: Enhancing Depth Perception in Vision-Language Models via Rationale-Guided Spatial Reasoning**&quot;.

<a href="https://arxiv.org/abs/2503.02310" target="_blank"><img src="https://img.shields.io/badge/IROS-2025-blue?style=for-the-badge"></a> Wenxuan Song, Jiayi Chen, Pengxiang Ding, <u>Han Zhao</u>, Wei Zhao, Zhide Zhong, Zongyuan Ge, Jun Ma, Haoang Li\*, &quot;**Accelerating Vision-Language-Action Model Integrated with Action Chunking via Parallel Decoding**&quot;. [[ArXiv](https://arxiv.org/pdf/2503.02310.pdf)]

<a href="https://arxiv.org/abs/2412.15576" target="_blank"><img src="https://img.shields.io/badge/ICRA-2025-blue?style=for-the-badge"></a> Xinyang Tong, Pengxiang Ding, Yiguo Fan, Donglin Wang\*, Wenjie Zhang, Can Cui, Mingyang Sun, <u>Han Zhao</u>, Hongyin Zhang, Yonghao Dang, Siteng Huang, Shangke Lyu, &quot;**QUART-Online: Latency-Free Large Multimodal Language Model for Quadruped Robot Learning**&quot;. [[ArXiv](https://arxiv.org/pdf/2412.15576.pdf)] [[project page](https://quart-online.github.io/)]

<a href="https://arxiv.org/abs/2503.08007" target="_blank"><img src="https://img.shields.io/badge/ICRA-2025-blue?style=for-the-badge"></a> <u>Han Zhao</u>, Wenxuan Song, Donglin Wang\*, Xinyang Tong, Pengxiang Ding, Xuelian Cheng, Zongyuan Ge, &quot;**MoRE: Unlocking Scalability in Reinforcement Learning for Quadruped Vision-Language-Action Models**&quot;. [[ArXiv](https://arxiv.org/pdf/2503.08007.pdf)]

<a href="https://arxiv.org/abs/2502.13508" target="_blank"><img src="https://img.shields.io/badge/ICLR-2025-blue?style=for-the-badge"></a> Wei Zhao, Pengxiang Ding, Min Zhang, Zhefei Gong, Shuanghao Bai, <u>Han Zhao</u>, Donglin Wang\*, &quot;**VLAS: Vision-Language-Action Model With Speech Instructions For Customized Robot Manipulation**&quot;. [[ArXiv](https://arxiv.org/pdf/2502.13508.pdf)]

<a href="https://www.sciencedirect.com/science/article/pii/S0925231225000359?via%3Dihub" target="_blank"><img src="https://img.shields.io/badge/Neuro-2025-green?style=for-the-badge"></a> Lei Guo\*, Wenbo Xiong, <u>Han Zhao</u>, Yuan Song, Dongming Gan, &quot;**A nearly optimal adaptive saturation function tuning method for quasi-sliding mode control based on integral reinforcement learning**&quot;. [[paper](https://www.sciencedirect.com/science/article/pii/S0925231225000359?via%3Dihub)]

<a href="https://arxiv.org/abs/2403.14520" target="_blank"><img src="https://img.shields.io/badge/AAAI-2025-blue?style=for-the-badge"></a> <u>Han Zhao</u>, Min Zhang, Wei Zhao, Pengxiang Ding, Siteng Huang, Donglin Wang\*, &quot;**Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference**&quot;. [[ArXiv](https://arxiv.org/pdf/2403.14520.pdf)] [[project page](https://sites.google.com/view/cobravlm)] [[zhihu](https://zhuanlan.zhihu.com/p/688544752)] [[github](https://github.com/h-zhao1997/cobra)] [[demo](https://huggingface.co/spaces/han1997/cobra)] [[twitter@AK](https://twitter.com/_akhaliq/status/1771033002748837953?t=6S4PVZXg6GcXqi_-PFzipw&s=19)]

### 2024
<a href="https://arxiv.org/abs/2312.14457" target="_blank"><img src="https://img.shields.io/badge/ECCV-2024-blue?style=for-the-badge"></a> Pengxiang Ding, <u>Han Zhao</u>, Wenjie Zhang, Wenxuan Song, Min Zhang, Siteng Huang, Ningxi Yang, Donglin Wang\*, &quot;**QUAR-VLA: Vision-Language-Action Model for Quadruped Robots**&quot;. [[ArXiv](https://arxiv.org/abs/2312.14457)]

<a href="https://arxiv.org/abs/2409.07239" target="_blank"><img src="https://img.shields.io/badge/ECCV-2024-blue?style=for-the-badge"></a> Yang Liu, Pengxiang Ding, Siteng Huang, Min Zhang, <u>Han Zhao</u>, Donglin Wang\*, &quot;**PiTe: Pixel-Temporal Alignment for Large Video-Language Model**&quot;. [[ArXiv](https://arxiv.org/abs/2409.07239)]

<a href="https://arxiv.org/abs/2403.13358" target="_blank"><img src="https://img.shields.io/badge/IROS-2024-blue?style=for-the-badge"></a> Wenxuan Song, <u>Han Zhao</u>, Pengxiang Ding, Can Cui, Shangke Lyu, Yaning Fan, Donglin Wang\*, &quot;**GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped Robot**&quot;. [[ArXiv](https://arxiv.org/abs/2403.13358)] [[project page](https://songwxuan.github.io/GeRM/)] [[video](https://www.youtube.com/watch?v=tjgIxsXW0JU)]

<a target="_blank"><img src="https://img.shields.io/badge/RSS-2024-blue?style=for-the-badge"></a> Shangke Lyu, Xin Lang, <u>Han Zhao</u>, Hongyin Zhang, Pengxiang Ding, Donglin Wang\*, &quot;**RL2AC: Reinforcement Learning-based Rapid Online Adaptive Control for Legged Robot Robust Locomotion**&quot;.

### 2023
<a href="https://ieeexplore.ieee.org/document/10341908/" target="_blank"><img src="https://img.shields.io/badge/IROS-2023-blue?style=for-the-badge"></a> Shangke Lyu, <u>Han Zhao</u>, Donglin Wang\*, &quot;**A Composite Control Strategy for Quadruped Robot by Integrating Reinforcement Learning and Model-Based Control**&quot;. [[paper](https://ieeexplore.ieee.org/document/10341908/)]

<a href="https://www.sciencedirect.com/science/article/abs/pii/S092523122201431X/" target="_blank"><img src="https://img.shields.io/badge/Neuro-2023-green?style=for-the-badge"></a> Lei Guo\*, <u>Han Zhao</u>, &quot;**Online adaptive optimal control algorithm based on synchronous integral reinforcement learning with explorations**&quot;. [[paper](https://www.sciencedirect.com/science/article/abs/pii/S092523122201431X/)]

<a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/cth2.12376/" target="_blank"><img src="https://img.shields.io/badge/IET%20CTA-2023-green?style=for-the-badge"></a> Lei Guo\*, <u>Han Zhao</u>, &quot;**Model‐free adaptive optimal control of continuous‐time nonlinear non‐zero‐sum games based on reinforcement learning**&quot;. [[paper](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/cth2.12376/)]

### 2022
<a href="https://ieeexplore.ieee.org/document/10033602/" target="_blank"><img src="https://img.shields.io/badge/CCDC-2022-blue?style=for-the-badge"></a> <u>Han Zhao*</u>, Lei Guo, Yuan Song, &quot;**System Modelling and Controller Design of a Variable Structure Two-Wheeled Robot Using Robust Adaptive Dynamic Programming**&quot;. [[paper](https://ieeexplore.ieee.org/document/10033602)]

<a href="https://ieeexplore.ieee.org/document/9902515/" target="_blank"><img src="https://img.shields.io/badge/CCC-2022-blue?style=for-the-badge"></a> <u>Han Zhao*</u>, Lei Guo, &quot;**Model-free Nearly Optimal Control of Constrained-Input Nonlinear Systems Based on Synchronous Reinforcement Learning**&quot;. [[paper](https://ieeexplore.ieee.org/document/9902515/)]


<h2 id='service'>Service</h2>

Reviewer for:

### Journal
- Knowledge-Based Systems (KBS)
- IET Control Theory & Applications (IET-CTA)

### Conference
- IEEE/CVF International Conference on Computer Vision (ICCV)
- AAAI Conference on Artificial Intelligence (AAAI)
- IEEE International Conference on Robotics and Automation (ICRA)
- IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
- IEEE Conference on Decision and Control (CDC)
